{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd621707-4e20-44ec-8969-647cde94c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0213610c-836f-40c2-a0e0-664b5483788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('insurance.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38cc00a-201a-4178-8290-307bb76764d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400        True     False      False   \n",
       "1      18  33.770         1   1725.55230       False      True       True   \n",
       "2      28  33.000         3   4449.46200       False      True       True   \n",
       "3      33  22.705         0  21984.47061       False      True       True   \n",
       "4      32  28.880         0   3866.85520       False      True       True   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830       False      True       True   \n",
       "1334   18  31.920         0   2205.98080        True     False       True   \n",
       "1335   18  36.850         0   1629.83350        True     False       True   \n",
       "1336   21  25.800         0   2007.94500        True     False       True   \n",
       "1337   61  29.070         0  29141.36030        True     False      False   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           True             False             False             False   \n",
       "1          False             False             False              True   \n",
       "2          False             False             False              True   \n",
       "3          False             False              True             False   \n",
       "4          False             False              True             False   \n",
       "...          ...               ...               ...               ...   \n",
       "1333       False             False              True             False   \n",
       "1334       False              True             False             False   \n",
       "1335       False             False             False              True   \n",
       "1336       False             False             False             False   \n",
       "1337        True             False              True             False   \n",
       "\n",
       "      region_southwest  \n",
       "0                 True  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "1333             False  \n",
       "1334             False  \n",
       "1335             False  \n",
       "1336              True  \n",
       "1337             False  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_data =  pd.get_dummies(data)\n",
    "one_hot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d8e41d-0c53-491c-8fd5-28a439509baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               1338 non-null   int64  \n",
      " 1   bmi               1338 non-null   float64\n",
      " 2   children          1338 non-null   int64  \n",
      " 3   charges           1338 non-null   float64\n",
      " 4   sex_female        1338 non-null   bool   \n",
      " 5   sex_male          1338 non-null   bool   \n",
      " 6   smoker_no         1338 non-null   bool   \n",
      " 7   smoker_yes        1338 non-null   bool   \n",
      " 8   region_northeast  1338 non-null   bool   \n",
      " 9   region_northwest  1338 non-null   bool   \n",
      " 10  region_southeast  1338 non-null   bool   \n",
      " 11  region_southwest  1338 non-null   bool   \n",
      "dtypes: bool(8), float64(2), int64(2)\n",
      "memory usage: 52.4 KB\n"
     ]
    }
   ],
   "source": [
    "one_hot_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04186076-0ee6-45a8-bb40-2f69285f24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = one_hot_data.drop(columns=('charges'))\n",
    "y = one_hot_data['charges']\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6f0dfb-0b52-4019-96d4-b2f53424fa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 10298.1191 - mae: 10298.1191\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 7493.7559 - mae: 7493.7559\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 7406.4634 - mae: 7406.4634\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 7322.8613 - mae: 7322.8613\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 7472.8311 - mae: 7472.8311\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 7331.7583 - mae: 7331.7583\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 7243.0601 - mae: 7243.0601\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7673.0386 - mae: 7673.0386\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 7490.6011 - mae: 7490.6011\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 7389.5640 - mae: 7389.5640\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 7629.0996 - mae: 7629.0996\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7930.6265 - mae: 7930.6265\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 7518.7808 - mae: 7518.7808\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 7598.4404 - mae: 7598.4404\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 7610.6982 - mae: 7610.6982\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7564.1904 - mae: 7564.1904\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 7551.9043 - mae: 7551.9043\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 7066.2559 - mae: 7066.2559\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7122.2881 - mae: 7122.2881\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 7465.4146 - mae: 7465.4146\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7333.7144 - mae: 7333.7144\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 7539.0688 - mae: 7539.0688\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 7477.9868 - mae: 7477.9868\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7314.0391 - mae: 7314.0391\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 7516.6201 - mae: 7516.6201\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 7473.9829 - mae: 7473.9829\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 7478.6172 - mae: 7478.6172\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7228.1328 - mae: 7228.1328\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 7142.9624 - mae: 7142.9624\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 7597.8174 - mae: 7597.8174\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 7033.5371 - mae: 7033.5371\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 7282.7197 - mae: 7282.7197\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7305.0386 - mae: 7305.0386\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 7488.0562 - mae: 7488.0562 \n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 7549.8628 - mae: 7549.8628\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 7515.8467 - mae: 7515.8467\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 7554.2378 - mae: 7554.2378\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - loss: 7249.3643 - mae: 7249.3643\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 7526.4087 - mae: 7526.4087\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 7383.0894 - mae: 7383.0894\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 7336.2456 - mae: 7336.2456\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7434.7871 - mae: 7434.7871\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 7240.6650 - mae: 7240.6650\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 7456.6123 - mae: 7456.6123\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 6958.0366 - mae: 6958.0366 \n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 7458.3599 - mae: 7458.3599\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 7001.4272 - mae: 7001.4272\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 7286.8291 - mae: 7286.8291\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 7283.1167 - mae: 7283.1167\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 7435.1538 - mae: 7435.1538\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 7330.3521 - mae: 7330.3521\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 7398.6377 - mae: 7398.6377\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 7419.9180 - mae: 7419.9180\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 7486.6318 - mae: 7486.6318\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 7653.0352 - mae: 7653.0352\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 7195.6377 - mae: 7195.6377\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7333.0625 - mae: 7333.0625\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 7427.6094 - mae: 7427.6094\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7644.8555 - mae: 7644.8555\n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 7385.8784 - mae: 7385.8784\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 7348.0742 - mae: 7348.0742\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 7414.4058 - mae: 7414.4058\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 7449.8975 - mae: 7449.8975\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 7345.0771 - mae: 7345.0771\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 7309.8789 - mae: 7309.8789\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 7274.3667 - mae: 7274.3667\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 7201.0674 - mae: 7201.0674\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 7329.7412 - mae: 7329.7412\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 7617.6943 - mae: 7617.6943\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 7225.3325 - mae: 7225.3325\n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 7306.4326 - mae: 7306.4326\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 7354.1968 - mae: 7354.1968\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7159.5269 - mae: 7159.5269\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 7156.2637 - mae: 7156.2637\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 7349.1548 - mae: 7349.1548\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7413.1177 - mae: 7413.1177\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7246.5259 - mae: 7246.5259\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 7316.1724 - mae: 7316.1724\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 7253.1108 - mae: 7253.1108\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 7268.4478 - mae: 7268.4478\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7528.6572 - mae: 7528.6572\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 6913.7607 - mae: 6913.7607\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 7229.9521 - mae: 7229.9521\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7420.5981 - mae: 7420.5981\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - loss: 7055.0181 - mae: 7055.0181\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 7003.1978 - mae: 7003.1978\n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7067.1260 - mae: 7067.1260\n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 6843.8384 - mae: 6843.8384\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 7331.2256 - mae: 7331.2256\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 7352.9902 - mae: 7352.9902\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 6797.4897 - mae: 6797.4897\n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 7477.6187 - mae: 7477.6187\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 7223.5029 - mae: 7223.5029\n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 7157.3628 - mae: 7157.3628\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 6937.7622 - mae: 6937.7622\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7079.4678 - mae: 7079.4678\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 7237.9194 - mae: 7237.9194\n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 7347.6685 - mae: 7347.6685\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 7217.0474 - mae: 7217.0474\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 6958.7090 - mae: 6958.7090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25605f72600>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a neural network (sort of like model_2_above)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Fit the Model\n",
    "model_1.fit(x_train , y_train , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4065365f-7599-47a4-a7f7-ea35c3e77a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 8182.8677 - mae: 8182.8677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8159.63427734375, 8159.63427734375]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c1b5bd-1308-45be-9189-0a086ef0b56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364485)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median() , y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21c9ca-2f13-400d-8c51-61c9d6c30f37",
   "metadata": {},
   "source": [
    "# now look with more layers and neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c912ff-41f6-453f-8b5d-389a50226e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: nan - mae: nan             \n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan \n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan \n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan \n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: nan - mae: nan \n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan \n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan \n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: nan - mae: nan \n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2560b4a5100>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100), \n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(x_train , y_train , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea8dea5-a618-4f3e-a189-c63ff2ea71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 13225.7422 - mae: 13225.7422\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 13055.6191 - mae: 13055.6191\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 12687.9893 - mae: 12687.9893\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 12015.4199 - mae: 12015.4199\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 10868.6025 - mae: 10868.6025\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 9435.8379 - mae: 9435.8379 \n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8124.1553 - mae: 8124.1553\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7484.2358 - mae: 7484.2358\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7390.7539 - mae: 7390.7539\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 7365.0327 - mae: 7365.0327\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 7343.5464 - mae: 7343.5464\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 7329.6357 - mae: 7329.6357\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7299.5825 - mae: 7299.5825\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 7276.9526 - mae: 7276.9526\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7254.4058 - mae: 7254.4058\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 7231.7485 - mae: 7231.7485\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7208.1743 - mae: 7208.1743\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7184.1577 - mae: 7184.1577\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 7160.1001 - mae: 7160.1001\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 7135.4917 - mae: 7135.4917\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 7110.0610 - mae: 7110.0610\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 7083.9233 - mae: 7083.9233\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7056.8154 - mae: 7056.8154\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 7028.7852 - mae: 7028.7852\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 6996.7617 - mae: 6996.7617\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 6971.9712 - mae: 6971.9712\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 6942.5391 - mae: 6942.5391\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6911.5664 - mae: 6911.5664\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 6880.1260 - mae: 6880.1260\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 6867.3394 - mae: 6867.3394\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 6842.3340 - mae: 6842.3340 \n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 6780.0371 - mae: 6780.0371\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 6740.5518 - mae: 6740.5518\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6738.5532 - mae: 6738.5532\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 6673.6416 - mae: 6673.6416\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 6635.3672 - mae: 6635.3672\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6592.1636 - mae: 6592.1636\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 6557.2456 - mae: 6557.2456\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 6518.9624 - mae: 6518.9624 \n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 6508.3394 - mae: 6508.3394\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 6444.2178 - mae: 6444.2178\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 6413.6470 - mae: 6413.6470\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 6387.2188 - mae: 6387.2188\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 6371.0615 - mae: 6371.0615\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 6336.9634 - mae: 6336.9634\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 6330.9443 - mae: 6330.9443\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 6315.3853 - mae: 6315.3853\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6294.9268 - mae: 6294.9268\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 6275.2891 - mae: 6275.2891\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 6253.2866 - mae: 6253.2866\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 6259.9380 - mae: 6259.9380\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6246.7773 - mae: 6246.7773\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 6233.3799 - mae: 6233.3799\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6219.4756 - mae: 6219.4756\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 6205.6392 - mae: 6205.6392 \n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 6191.2124 - mae: 6191.2124\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 6176.6953 - mae: 6176.6953\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 6209.0752 - mae: 6209.0752\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 6146.5078 - mae: 6146.5078 \n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 6132.5386 - mae: 6132.5386\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 6135.7266 - mae: 6135.7266 \n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 6098.7998 - mae: 6098.7998\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6074.9131 - mae: 6074.9131\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6085.1812 - mae: 6085.1812\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 6059.7495 - mae: 6059.7495\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 6028.6309 - mae: 6028.6309\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 6010.4062 - mae: 6010.4062\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 5991.1357 - mae: 5991.1357\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 5971.8813 - mae: 5971.8813\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 5944.5767 - mae: 5944.5767\n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5930.5977 - mae: 5930.5977\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 5894.4126 - mae: 5894.4126\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 5886.4438 - mae: 5886.4438\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 5879.9380 - mae: 5879.9380\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 5839.9404 - mae: 5839.9404\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 5815.2041 - mae: 5815.2041\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 5791.3833 - mae: 5791.3833\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5768.4834 - mae: 5768.4834\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 5737.1191 - mae: 5737.1191\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 5706.3354 - mae: 5706.3354\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 5672.3535 - mae: 5672.3535\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 5671.7261 - mae: 5671.7261\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 5605.9502 - mae: 5605.9502\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 5578.6738 - mae: 5578.6738\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 5549.2271 - mae: 5549.2271\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 5507.8833 - mae: 5507.8833 \n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 5469.8320 - mae: 5469.8320 \n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 5429.3818 - mae: 5429.3818\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 5386.3765 - mae: 5386.3765\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 5341.1284 - mae: 5341.1284\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 5292.2837 - mae: 5292.2837 \n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 5248.6196 - mae: 5248.6196\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 5195.5342 - mae: 5195.5342 \n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 5141.9326 - mae: 5141.9326\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 5075.2109 - mae: 5075.2109\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 5027.5122 - mae: 5027.5122\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 4963.9058 - mae: 4963.9058 \n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 4898.4307 - mae: 4898.4307\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 4828.9556 - mae: 4828.9556\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 4757.5649 - mae: 4757.5649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2560ad65970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100), \n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(x_train , y_train , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1140a1d3-14d2-462d-a687-d2446e2ed16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4881.2188 - mae: 4881.2188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4742.43701171875, 4742.43701171875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69d2847a-dad8-4962-aa32-da9ef79d6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 13280.6348 - mae: 13280.6348\n",
      "Epoch 2/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 13139.1758 - mae: 13139.1758\n",
      "Epoch 3/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 12848.1807 - mae: 12848.1807\n",
      "Epoch 4/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 12274.8115 - mae: 12274.8115\n",
      "Epoch 5/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 11203.3613 - mae: 11203.3613\n",
      "Epoch 6/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 9823.8945 - mae: 9823.8945  \n",
      "Epoch 7/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 8356.6172 - mae: 8356.6172\n",
      "Epoch 8/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7550.1519 - mae: 7550.1519\n",
      "Epoch 9/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7412.5166 - mae: 7412.5166\n",
      "Epoch 10/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 7384.6108 - mae: 7384.6108\n",
      "Epoch 11/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 7363.1714 - mae: 7363.1714 \n",
      "Epoch 12/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 7364.5903 - mae: 7364.5903\n",
      "Epoch 13/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7341.0234 - mae: 7341.0234\n",
      "Epoch 14/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 7297.2837 - mae: 7297.2837\n",
      "Epoch 15/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 7285.6812 - mae: 7285.6812\n",
      "Epoch 16/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 7274.5767 - mae: 7274.5767 \n",
      "Epoch 17/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 7228.7656 - mae: 7228.7656\n",
      "Epoch 18/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 7205.4141 - mae: 7205.4141\n",
      "Epoch 19/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 7181.4009 - mae: 7181.4009\n",
      "Epoch 20/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 7157.5913 - mae: 7157.5913\n",
      "Epoch 21/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 7133.0645 - mae: 7133.0645\n",
      "Epoch 22/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7107.6201 - mae: 7107.6201\n",
      "Epoch 23/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 7081.4067 - mae: 7081.4067\n",
      "Epoch 24/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 7054.7251 - mae: 7054.7251\n",
      "Epoch 25/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 7025.8042 - mae: 7025.8042\n",
      "Epoch 26/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6998.6235 - mae: 6998.6235\n",
      "Epoch 27/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6970.2520 - mae: 6970.2520\n",
      "Epoch 28/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 6946.4575 - mae: 6946.4575\n",
      "Epoch 29/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 6911.1343 - mae: 6911.1343\n",
      "Epoch 30/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 6879.6616 - mae: 6879.6616\n",
      "Epoch 31/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 6836.7935 - mae: 6836.7935\n",
      "Epoch 32/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 6803.1528 - mae: 6803.1528\n",
      "Epoch 33/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 6779.7183 - mae: 6779.7183\n",
      "Epoch 34/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 6745.5737 - mae: 6745.5737 \n",
      "Epoch 35/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 6728.2998 - mae: 6728.2998\n",
      "Epoch 36/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 6691.9473 - mae: 6691.9473\n",
      "Epoch 37/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 6636.5859 - mae: 6636.5859\n",
      "Epoch 38/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6597.8682 - mae: 6597.8682\n",
      "Epoch 39/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6548.2905 - mae: 6548.2905\n",
      "Epoch 40/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 6520.7642 - mae: 6520.7642\n",
      "Epoch 41/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 6465.3398 - mae: 6465.3398 \n",
      "Epoch 42/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 6446.6987 - mae: 6446.6987\n",
      "Epoch 43/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 6415.0918 - mae: 6415.0918\n",
      "Epoch 44/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 6405.4043 - mae: 6405.4043\n",
      "Epoch 45/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 6367.4033 - mae: 6367.4033\n",
      "Epoch 46/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 6348.3804 - mae: 6348.3804\n",
      "Epoch 47/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 6333.6465 - mae: 6333.6465\n",
      "Epoch 48/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 6299.8291 - mae: 6299.8291\n",
      "Epoch 49/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6295.3828 - mae: 6295.3828\n",
      "Epoch 50/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6315.8398 - mae: 6315.8398\n",
      "Epoch 51/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6275.5996 - mae: 6275.5996\n",
      "Epoch 52/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 6257.4907 - mae: 6257.4907\n",
      "Epoch 53/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 6249.5103 - mae: 6249.5103\n",
      "Epoch 54/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 6231.3105 - mae: 6231.3105\n",
      "Epoch 55/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 6203.8003 - mae: 6203.8003\n",
      "Epoch 56/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 6216.3188 - mae: 6216.3188\n",
      "Epoch 57/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 6195.4341 - mae: 6195.4341\n",
      "Epoch 58/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 6181.0415 - mae: 6181.0415\n",
      "Epoch 59/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6166.4043 - mae: 6166.4043\n",
      "Epoch 60/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 6151.3721 - mae: 6151.3721\n",
      "Epoch 61/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 6136.0850 - mae: 6136.0850\n",
      "Epoch 62/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 6113.4111 - mae: 6113.4111\n",
      "Epoch 63/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 6104.5391 - mae: 6104.5391\n",
      "Epoch 64/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 6088.1475 - mae: 6088.1475\n",
      "Epoch 65/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 6071.2310 - mae: 6071.2310\n",
      "Epoch 66/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 6034.3140 - mae: 6034.3140\n",
      "Epoch 67/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 6017.0928 - mae: 6017.0928\n",
      "Epoch 68/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 6022.9277 - mae: 6022.9277\n",
      "Epoch 69/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 5999.1973 - mae: 5999.1973\n",
      "Epoch 70/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 5980.1167 - mae: 5980.1167\n",
      "Epoch 71/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 5960.2593 - mae: 5960.2593 \n",
      "Epoch 72/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 5945.5518 - mae: 5945.5518\n",
      "Epoch 73/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5918.5830 - mae: 5918.5830\n",
      "Epoch 74/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 5897.1328 - mae: 5897.1328\n",
      "Epoch 75/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 5874.7700 - mae: 5874.7700\n",
      "Epoch 76/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 5851.1538 - mae: 5851.1538\n",
      "Epoch 77/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 5827.1255 - mae: 5827.1255\n",
      "Epoch 78/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 5802.0020 - mae: 5802.0020\n",
      "Epoch 79/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 5771.0664 - mae: 5771.0664\n",
      "Epoch 80/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 5741.6221 - mae: 5741.6221\n",
      "Epoch 81/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 5720.3799 - mae: 5720.3799\n",
      "Epoch 82/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 5691.1226 - mae: 5691.1226\n",
      "Epoch 83/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 5644.1221 - mae: 5644.1221\n",
      "Epoch 84/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 5629.1279 - mae: 5629.1279\n",
      "Epoch 85/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 5620.0298 - mae: 5620.0298\n",
      "Epoch 86/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 5560.8359 - mae: 5560.8359\n",
      "Epoch 87/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 5545.5337 - mae: 5545.5337\n",
      "Epoch 88/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 5487.7148 - mae: 5487.7148\n",
      "Epoch 89/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 5448.0762 - mae: 5448.0762\n",
      "Epoch 90/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 5407.1064 - mae: 5407.1064\n",
      "Epoch 91/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 5348.8398 - mae: 5348.8398\n",
      "Epoch 92/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 5338.1226 - mae: 5338.1226 \n",
      "Epoch 93/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 5272.6499 - mae: 5272.6499\n",
      "Epoch 94/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 5222.5093 - mae: 5222.5093\n",
      "Epoch 95/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 5167.4292 - mae: 5167.4292\n",
      "Epoch 96/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 5116.1880 - mae: 5116.1880\n",
      "Epoch 97/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 5056.1484 - mae: 5056.1484\n",
      "Epoch 98/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 4994.8198 - mae: 4994.8198\n",
      "Epoch 99/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 4929.8452 - mae: 4929.8452\n",
      "Epoch 100/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 4863.2964 - mae: 4863.2964\n",
      "Epoch 101/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 4791.4946 - mae: 4791.4946\n",
      "Epoch 102/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 4708.0503 - mae: 4708.0503\n",
      "Epoch 103/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 4641.8921 - mae: 4641.8921\n",
      "Epoch 104/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 4562.6445 - mae: 4562.6445\n",
      "Epoch 105/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 4475.4409 - mae: 4475.4409\n",
      "Epoch 106/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 4387.2368 - mae: 4387.2368\n",
      "Epoch 107/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 4295.0479 - mae: 4295.0479\n",
      "Epoch 108/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 4211.7534 - mae: 4211.7534\n",
      "Epoch 109/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 4119.8857 - mae: 4119.8857\n",
      "Epoch 110/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 4051.0515 - mae: 4051.0515\n",
      "Epoch 111/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 3959.9829 - mae: 3959.9829\n",
      "Epoch 112/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 3907.2070 - mae: 3907.2070\n",
      "Epoch 113/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 3851.6792 - mae: 3851.6792\n",
      "Epoch 114/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 3827.9304 - mae: 3827.9304\n",
      "Epoch 115/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 3788.8513 - mae: 3788.8513\n",
      "Epoch 116/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 3779.4102 - mae: 3779.4102\n",
      "Epoch 117/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 3757.3865 - mae: 3757.3865\n",
      "Epoch 118/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 3757.0620 - mae: 3757.0620\n",
      "Epoch 119/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 3746.6619 - mae: 3746.6619\n",
      "Epoch 120/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 3751.0762 - mae: 3751.0762\n",
      "Epoch 121/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 3734.9478 - mae: 3734.9478\n",
      "Epoch 122/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 3731.0168 - mae: 3731.0168\n",
      "Epoch 123/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 3724.9614 - mae: 3724.9614\n",
      "Epoch 124/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 3722.1443 - mae: 3722.1443\n",
      "Epoch 125/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 3717.4226 - mae: 3717.4226\n",
      "Epoch 126/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 3715.0715 - mae: 3715.0715\n",
      "Epoch 127/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 3710.4414 - mae: 3710.4414\n",
      "Epoch 128/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 3709.1755 - mae: 3709.1755\n",
      "Epoch 129/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 3714.7566 - mae: 3714.7566\n",
      "Epoch 130/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 3699.6975 - mae: 3699.6975\n",
      "Epoch 131/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 3701.6550 - mae: 3701.6550\n",
      "Epoch 132/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 3699.6414 - mae: 3699.6414\n",
      "Epoch 133/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 3686.2690 - mae: 3686.2690\n",
      "Epoch 134/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 3696.4915 - mae: 3696.4915\n",
      "Epoch 135/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 3693.6013 - mae: 3693.6013\n",
      "Epoch 136/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 3691.2625 - mae: 3691.2625\n",
      "Epoch 137/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 3697.7673 - mae: 3697.7673\n",
      "Epoch 138/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 3688.4683 - mae: 3688.4683\n",
      "Epoch 139/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 3694.5039 - mae: 3694.5039 \n",
      "Epoch 140/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 3678.7769 - mae: 3678.7769\n",
      "Epoch 141/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 3683.5369 - mae: 3683.5369 \n",
      "Epoch 142/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 3681.9451 - mae: 3681.9451\n",
      "Epoch 143/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 3673.4954 - mae: 3673.4954\n",
      "Epoch 144/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 3678.4995 - mae: 3678.4995\n",
      "Epoch 145/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 3676.8269 - mae: 3676.8269\n",
      "Epoch 146/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 3683.7996 - mae: 3683.7996\n",
      "Epoch 147/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 3671.7302 - mae: 3671.7302\n",
      "Epoch 148/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 3685.7581 - mae: 3685.7581\n",
      "Epoch 149/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 3672.4995 - mae: 3672.4995\n",
      "Epoch 150/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 3667.5208 - mae: 3667.5208\n",
      "Epoch 151/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 3669.5408 - mae: 3669.5408\n",
      "Epoch 152/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 3667.5793 - mae: 3667.5793\n",
      "Epoch 153/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 3663.3059 - mae: 3663.3059\n",
      "Epoch 154/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 3668.4395 - mae: 3668.4395\n",
      "Epoch 155/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 3663.9290 - mae: 3663.9290\n",
      "Epoch 156/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 3661.9031 - mae: 3661.9031\n",
      "Epoch 157/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 3661.9592 - mae: 3661.9592\n",
      "Epoch 158/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 3663.8459 - mae: 3663.8459\n",
      "Epoch 159/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 3652.4001 - mae: 3652.4001\n",
      "Epoch 160/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 3656.7136 - mae: 3656.7136\n",
      "Epoch 161/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 3651.3286 - mae: 3651.3286\n",
      "Epoch 162/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 3657.2097 - mae: 3657.2097\n",
      "Epoch 163/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 3645.6821 - mae: 3645.6821\n",
      "Epoch 164/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 3651.2788 - mae: 3651.2788\n",
      "Epoch 165/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 3666.8171 - mae: 3666.8171\n",
      "Epoch 166/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 3649.5398 - mae: 3649.5398\n",
      "Epoch 167/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 3647.4609 - mae: 3647.4609\n",
      "Epoch 168/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 3647.7637 - mae: 3647.7637 \n",
      "Epoch 169/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 3647.4792 - mae: 3647.4792\n",
      "Epoch 170/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 3644.3325 - mae: 3644.3325\n",
      "Epoch 171/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 3644.1475 - mae: 3644.1475\n",
      "Epoch 172/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 3642.8503 - mae: 3642.8503\n",
      "Epoch 173/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 3642.1082 - mae: 3642.1082\n",
      "Epoch 174/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 3640.2854 - mae: 3640.2854 \n",
      "Epoch 175/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 3639.2129 - mae: 3639.2129\n",
      "Epoch 176/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 3640.9731 - mae: 3640.9731\n",
      "Epoch 177/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 3628.6506 - mae: 3628.6506\n",
      "Epoch 178/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 3638.0315 - mae: 3638.0315\n",
      "Epoch 179/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 3636.1445 - mae: 3636.1445\n",
      "Epoch 180/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 3643.7300 - mae: 3643.7300\n",
      "Epoch 181/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 3635.0322 - mae: 3635.0322\n",
      "Epoch 182/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 3633.7759 - mae: 3633.7759\n",
      "Epoch 183/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 3634.9258 - mae: 3634.9258\n",
      "Epoch 184/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 3631.7041 - mae: 3631.7041\n",
      "Epoch 185/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 3623.0750 - mae: 3623.0750\n",
      "Epoch 186/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 3628.5249 - mae: 3628.5249\n",
      "Epoch 187/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 3621.8452 - mae: 3621.8452\n",
      "Epoch 188/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 3615.3918 - mae: 3615.3918\n",
      "Epoch 189/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 3615.0242 - mae: 3615.0242\n",
      "Epoch 190/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 3624.9080 - mae: 3624.9080\n",
      "Epoch 191/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 3622.7854 - mae: 3622.7854\n",
      "Epoch 192/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 3622.4443 - mae: 3622.4443\n",
      "Epoch 193/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 3620.2466 - mae: 3620.2466\n",
      "Epoch 194/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 3612.1360 - mae: 3612.1360\n",
      "Epoch 195/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 3622.4524 - mae: 3622.4524\n",
      "Epoch 196/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 3618.0190 - mae: 3618.0190\n",
      "Epoch 197/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 3619.3030 - mae: 3619.3030\n",
      "Epoch 198/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 3612.2144 - mae: 3612.2144\n",
      "Epoch 199/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 3619.8589 - mae: 3619.8589\n",
      "Epoch 200/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 3615.0676 - mae: 3615.0676\n"
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1.Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1) \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = model_3.fit(x_train , y_train , epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5164b7a-5a84-4307-b088-c1499d313938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 3470.7222 - mae: 3470.7222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3405.598876953125, 3405.598876953125]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27f5377d-0962-48f6-9b12-bcf1c5dbdd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also Known as a loss curve or a training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c1a2c-ea8d-4630-8987-94e49b27b8cd",
   "metadata": {},
   "source": [
    "# Prepocessing data (Normalization and Standardization)\n",
    "## In terms of scaling calues, neural newtworks tend to prefer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd138938-0bfd-4f4c-b52f-576f61fa67dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_csv('insurance.csv')\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b474b1f2-9212-4482-99f5-774efe383d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;minmaxscaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;minmaxscaler&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">minmaxscaler</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;bmi&#x27;, &#x27;children&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehotencoder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;sex&#x27;, &#x27;smoker&#x27;, &#x27;region&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['age', 'bmi', 'children']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['sex', 'smoker', 'region'])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler() , ['age' , 'bmi' , 'children']), # turn all values in these columns between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown='ignore') , ['sex' , 'smoker' , 'region'])\n",
    ")\n",
    "\n",
    "# Create X and Y\n",
    "X = insurance.drop('charges' , axis=1)\n",
    "Y =  insurance['charges']\n",
    "\n",
    "# Build oyr train and test data\n",
    "X_train , Y_train , X_test , Y_test = train_test_split(X , Y , test_size=0.2 , random_state=42)\n",
    "\n",
    "# Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "# x_train_normal = ct.transform(X_train)\n",
    "# x_test_normal = ct.transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10507b8f-5c60-4cbb-8a2a-4a515ce53280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
